<!doctype html><head><script src="../eveal.js/eveal.js"></script></head><body>
<style>code { background-color:#eee; color:#900; }</style>


## Migrating Internet Archive
## to Kubernetes
### KubeCon 2018 - Seattle, WA

<small>
  @tracey_pooh<br>
  @dvanduzer<br>

  2018 December 13
</small>

<small>
  _?_ for keyboard shortcuts
</small><br>
https://github.com/traceypooh/slides

---
# the Internet Archive
## to Collect & to Serve

---
<!-- .slide: data-background="ia-truck-cartoon.jpg" -->
<img src="sign.png" style="position:absolute; right:0; top:-250px; min-width:300px; min-height:300px !important; background: 0"/>

<small style="position:fixed; bottom:0; color:white !important">credit: www.flickr.com/photos/cassidy/6898197626</small>

---
# Challenge of Big Changes
<img height="500" data-src="NWL_Press_DontIronWhileStrikeisHot_122116.jpg"/>

---
### What's in it for Us?
- language / platform / OS flexibility of Docker
- model to enforce rebuildable recipes
- more coding; less system building and admin
- avoid cpu excess/starvation from static resource allocation
- fewer "pet" servers
<a href="https://www.youtube.com/watch?time_continue=2&v=vTwJzTsb2QQ">
  <img data-src="i/herding-cats.jpg"/>
</a>

---
# Internet Archive
## a Digital Library
### Curate
### Preserve
### Circulate

---
# Curate all the things!
- 300B+ web pages _WayBack Machine_
- 15M books
- 4M videos & TV News programs
- 4M audio & concerts
- 3M images
- 200K software items & emulation
---
<a href="https://web.archive.org/web/19970404064352/http://www.apple.com:80/">
  <img style="max-height:700px" src="i/wayback-apple.png"/>
</a>
---
<a href="https://archive.org/details/goodytwoshoes00newyiala">
  <img style="max-height:700px" src="i/bookreader.jpg"/>
</a>
---
<a href="https://archive.org/details/msdos_Pac-Man_1983">
  <img style="max-height:700px" src="i/software.png"/>
</a>
---
<a href="https://archive.org/details/Sita_Sings_the_Blues">
  <img style="max-height:700px" src="i/av.jpg"/>
</a>

---
## Curation: First potential Kubernetes Uses
- book scanning apps
- crawl frontier management
- finite duration projects

---
# Preservation
- 50+ petabytes over 22 years
- Fourth generation storage system
- Independence by self-hosting
- Multi-datacenter replication

---
<!-- .slide: data-background="i/container-ship-sink.jpg" -->

---
## Example of Metadata
- Validation & nontampering
  - keep original versions with 2+ checksums and logs
```xml
<file name="commute.mp4" source="derivative">
  <title>commute</title>
  <format>h.264</format>
  <original>commute.avi</original>
  <md5>ff17ed66e7db5693dd208dd6ac488ff8</md5>
  <mtime>1325973601</mtime>
  <size>11919082</size>
  <crc32>ad1df03a</crc32>
  <sha1>e9f9de8379cd25653d487ab30d198fc61a050091</sha1>
  <length>115.61</length>
  <height>480</height>
  <width>640</width>
</file>
```

---
# .. But!
- still more comfortable w/ block-device storage than torrented pieces for entire data Archives
  - eg: S3 => K8 or o/w -- seems anxiety++

---
# Circulation
- 300B+ web pages _WayBack Machine_
- 15M books
- 4M videos & TV News programs
- 4M audio & concerts
- 3M images
- 200K software items & emulation

---
## xxx Somewhere in Circulation section
# Library!
- Absolute browser Privacy
  - no personal data or IP addresses extracted

---
## Timeline / Evolution
| Month | Progress
|:--- | ---
| 2014/11 | `docker` for audio fingerprints - controversial
| 2015/10 | `MozFest` OpenNews `docker` talk mind blown
| 2016/8  | switched `mp3/mp4` generation to `docker`
| 2017/6  | <a href="https://archive.org/~tracey/docker-talker">IA Engr. Presentation</a>
| 2018/6  | <a href="https://archive.org/~tracey/kubernetes-special-topic">IA Engr. Special Topic talk</a>
| 2018/7  | <a href="https://archive.org/~tracey/auto-devops">_GitLab 'Auto DevOps'_ Changes Everything - Dev & Ops Harmony - Confessions of a middle child</a>

---
# LogJam BreakThroughs
- TeamUp! (end of 2017)
  - David - ops-heavy history <img data-src="chocolate.png" style="vertical-align:middle"/>
  - Tracey - dev-heavy history <img data-src="peanut-butter.jpg" style="vertical-align:middle"/>
- GitLab advertises `with Kubernetes` July/2018
  - _already using_ 'on premise' `GitLab` for repos
  - w/ ssh-key user accounts .org-wide

---
## Timeline / Evolution
| Month | Moves into GitLab Auto DevOps Kubernetes
|:--- | ---
| 2018/8  | archive.org main repo CI/`test` migrated
| 2018/9  | archive.org full pipelines, <a href="https://ia-petabox.archive.org/">website 'review apps'</a>
| 2018/10 | bookscan webapps
| 2018/10 | moved to GitLab's docker registry
| 2018/12 | <a href="https://dweb.archive.org/">dweb.archive.org</a> (archive.org decentralized)

---
# Avoid Bad Blood
<a href="https://www.youtube.com/watch?v=QcIy9NiNbmo">
  <img data-src="bad-blood.jpg"/>
</a>

---
## Work Towards Common Goals
Devs & Ops
<a href="https://en.wikipedia.org/wiki/The_Uncanny_X-Men_and_The_New_Teen_Titans">
  <img data-src="harmony.jpg"/>
</a>

---
# www-NAME (bespoke) -v- review apps (GitLab + k8)
webapps quick development at archive.org

---
# www-tracey.archive.org
- ssh 'bastion' with homedirs
- NFS /home/ automounts throughout cluster
- edit:
  - emacs/vi on (linux) bastion
  - laptop editors with sftp / rsync-over-ssh on `[save]`
- nginx virtual hosts
  - https://archive.org => `/petabox/www/..` (production)
  - https://www-NAME.archive.org => `/home/NAME/petabox/www/..` (dev)

---
## www-NAME.archive.org issues
- single 'dest' (multiple branches tricky)
- ssh keys and acccess
- NFS /home/ dirs

---
## K8 + Auto DevOps 'review apps'
- contractors can work/test full site
  - w/o ssh keys/access
  - 12h timezone shift OK
    - no staff/approval need - `game changer!`
- git branches => 'review apps' consistent/update over time
- `kre8/branch-sync-edit.sh`
  - 'copy file change to pod on save' fast script
  - webapp instant f/b w/o full push and CI/CD

---
## Auto DevOps Pipelines
<img src="../auto-devops/pipeline.png"/>

---
# Crawling Case Study

---
## Anatomy of Archival Crawling
1. Start with a list of websites
2. Fetch all those URLs
3. Extract Hyperlinks from all the fetched content
  - Now you have a list of websites again
  - Which you can Fetch and Extract and...
4. Serialize captures into WARC (Web Archive) format
5. Persist to permanent item storage

---
## Heritrix
- open source Java crawler developed at IA
- very good at pipelining these stages
- but, single machine operation

## CrawlHQ
- distributed frontier management
- multiple Heritrix instances share single URL deduplication queue

---
## Rewriting CrawlHQ as Demo of K8S auto-scaling
- Kafka partitions for work queue
- FoundationDB for hashes of seen URLs
- 38,000 lines of code is now 73 lines of Python
- throughput scales automatically with GitLab `REPLICAS` variable

---
<!-- .slide: data-background="black" -->
<iframe src="https://archive.org/embed/kubecon-monolith" width="960" height="540" frameborder="0" webkitallowfullscreen="true" mozallowfullscreen="true" allowfullscreen></iframe>
<!-- video src="Monolith.mp4" autoplay controls mozallowfullscreen webkitallowfullscreen allowfullscreen -->

---
# Monolith Repo speed++
- 4.8G tree => 6GB .. 9GB docker images
- `test` phase _first_ = faster (when possible)
- takeover git mgmt
  - naive `git clone` every CI/CD phase = nonstarter

---
## petabox Repo Docker Images
|  |
| :-------: |
| `[petabase]` |
| Baseline docker image <br> Ubuntu LTS<br> pkgs <br> js/npm/yarn <br> php/pecl/pear <br> python/pip2/3 <br> petabox repo git _SHALLOW_ clone <br> CI `test` after git fast fwd |

---
|  |  |  |  |
| :-------: | :-------: | :-------: | :-------: |
| | `[petabase]` | | |
| ⬇ | ⬇ | ⬇ | ⬇ |
| `[workbase]` | `[webnode]` | `[dev]` | `[homenode]` |
| 3rd party deriver pkgs + config<br>ffmpeg ..| git fast fwd<br>archive.org<br>website<br>nginx+<br>supervisor | git fast fwd <br>empty DB/SE<br>daemons/supervisor<br>archive.org website<br>item store/process | git fast fwd<br>misc nodes |
| ⬇ | | | |
| `[worker]`  | | | |
| git fast fwd <br> mp3/mp4/etc | | | |


---
# Monolith repo speed++
- `[petabase]` baseline image recut every 1-4 weeks
  - git _shallow_ clone (2/3 size)
  - all usages 'fast forward' to branch &amp; commit
- `build` phase uses prior build
  - via registry docker pull for branch

---
# \* ** Monolith repo GIT ** \*
fast forward a git clone depth 1
- `git checkout --detach` <font color="gray">\*</font>
- `git fetch --depth 1 -f -origin [brnch|ca6745]`
- `git checkout -f [brnch|ca6745]`
  <font color="gray">\* avoid tangle with git tree state</font>

- Workaround 'advertised' commits issue (self-hosted GitLab)
  - ```omnibus_gitconfig['system'] = {"uploadpack" => ["allowReachableSHA1InWant = true"]}```
  - then able to fetch any commit

---
## because we have _this_ guy (and you don't)
<img data-src="git-pro.jpg"><br>
^ git pro


---
## 'on prem' K8 cluster from scratch
- https://gitlab.com/internetarchive/kre8
  <img style="width:10%; vertical-align:middle" data-src="i/pirate-coin-rotated-small.png"/>
  - `kubeadm` to create cluster
  - sets up GitLab 'Auto DevOps' CI/CD full pipeline
  - need 1+ VM w/ ssh access and sudo
    - (ubuntu based so far)
  - coworker can try out - low committment
  - `kallr`

---
# Top Tips
- can use simple `localstorage` for 1 or 2-node k8 clusters
- `POSTGRES_ENABLED=false` CI/CD var
  - avoids extra (unused!) PV per branch/deploy
- GitLab API for last master `test` phase status
  - 'OK to push live?'
- periodically:
  - remove old replicasets
  - trim registry

---
## LoadBalancer vs Ingress for Alt Ports
- `kubectl expose -ndweb deployment/production --type=LoadBalancer --name=porter`
- `kubectl patch  -ndweb svc/porter -p='{"spec":{"externalIPs":["'${K8_INGRESS_IP?}"]}}'`
- allows for non :80 :443 :5000 ports
  - websockets eg:
    - wss://dweb.me:4246

---
# Near Future

archive.org production website to K8

| | |
|:--- | ---
| now | static list of VMs + haproxy
| new | elastic demand-based scaling

---
<!-- .slide: data-background="https://media.giphy.com/media/Gdjgn0hy8zBRK/giphy.gif" -->
# The End

